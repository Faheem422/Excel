{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SX1YuKQ4UDon"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Each item is one sentence so we have 7 sentence\n",
        "docs = ['go pakistan',\n",
        "\t\t'pakistan pakistan',\n",
        "\t\t'hip hip hurray',\n",
        "\t\t'jeetega bhai jeetega pakistan jeetega',\n",
        "\t\t'pakistan zindabad',\n",
        "\t\t'babar azam',\n",
        "\t\t'afridi afridi']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First Step is to tokenize tour data (Means if theres capital letter in sentence you have to make it im small, remove special symbols)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<nothing>')    #out of vocabluray token (Each new word will be replace by nothing )"
      ],
      "metadata": {
        "id": "pOJzJ3vzUOkh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "njO0da4-Unl8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index #Each unique word is tokenize by numbers"
      ],
      "metadata": {
        "id": "GrKpFbzRUucs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f04a05-4967-4d08-acf6-bc207af769dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<nothing>': 1,\n",
              " 'pakistan': 2,\n",
              " 'jeetega': 3,\n",
              " 'hip': 4,\n",
              " 'afridi': 5,\n",
              " 'go': 6,\n",
              " 'hurray': 7,\n",
              " 'bhai': 8,\n",
              " 'zindabad': 9,\n",
              " 'babar': 10,\n",
              " 'azam': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_counts #Find the frequency of word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNcKSYUYegGl",
        "outputId": "bbec8f47-752c-492f-9739-8998dbb9f4ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('go', 1),\n",
              "             ('pakistan', 5),\n",
              "             ('hip', 2),\n",
              "             ('hurray', 1),\n",
              "             ('jeetega', 3),\n",
              "             ('bhai', 1),\n",
              "             ('zindabad', 1),\n",
              "             ('babar', 1),\n",
              "             ('azam', 1),\n",
              "             ('afridi', 2)])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.document_count # To find no of sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx3SMLV3euuU",
        "outputId": "bc05f186-677d-40bf-ca55-b8712f4488e9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)  # to generate sequences for text\n",
        "sequences"
      ],
      "metadata": {
        "id": "xNrqCeiUU05s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f454bb62-351f-467f-db55-72b68d12a1a9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 2], [2, 2], [4, 4, 7], [3, 8, 3, 2, 3], [2, 9], [10, 11], [5, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences # Because sequences are of diffent sizes"
      ],
      "metadata": {
        "id": "Y15DVHzhVCEY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pad_sequences(sequences,padding='post') # so we need to apply the paddings"
      ],
      "metadata": {
        "id": "H00D6kZlVOC4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjL4mCzTV4rT",
        "outputId": "bdd9e7c1-cafd-4440-8073-d74b7b2103a9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  2,  0,  0,  0],\n",
              "       [ 2,  2,  0,  0,  0],\n",
              "       [ 4,  4,  7,  0,  0],\n",
              "       [ 3,  8,  3,  2,  3],\n",
              "       [ 2,  9,  0,  0,  0],\n",
              "       [10, 11,  0,  0,  0],\n",
              "       [ 5,  5,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
      ],
      "metadata": {
        "id": "f4cMDq3KDiaC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test) = imdb.load_data()"
      ],
      "metadata": {
        "id": "vVqDOLaefsom"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape) # No of reviews in training\n",
        "X_train[0] # first review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTk54ntQfu6W",
        "outputId": "cf896b02-45e8-433d-bd7a-ff74d9daddd4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,\n",
              "         21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,\n",
              "         36,   28,  224,   92,   25,  104,    4,  226,   65,   16,   38,\n",
              "       1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,\n",
              "         15,   16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9tGLS4ofzBu",
        "outputId": "6bb00902-b253-4ae6-f56c-6e660dcd9c1e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train,padding='post',maxlen=50) # each review will be trim by 50 words to avoid long training time\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=50)"
      ],
      "metadata": {
        "id": "uoEmzhEhf1aV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4kNirFSgDEe",
        "outputId": "f681837a-109e-4042-cc16-2ebacb6c6cec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,\n",
              "         21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,\n",
              "         36,   28,  224,   92,   25,  104,    4,  226,   65,   16,   38,\n",
              "       1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,\n",
              "         15,   16, 5345,   19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(32,input_shape=(50,1),return_sequences=False))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN_Fi3n6gFkp",
        "outputId": "0027c8d7-f872-412a-e1a7-46d2377d55d8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 32)                1088      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1121 (4.38 KB)\n",
            "Trainable params: 1121 (4.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EArIjALcgPTh",
        "outputId": "e7e9c2b5-c370-4ccc-d01d-729323f501e6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 19s 20ms/step - loss: 0.6947 - accuracy: 0.5037 - val_loss: 0.6948 - val_accuracy: 0.5056\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6933 - accuracy: 0.5094 - val_loss: 0.6937 - val_accuracy: 0.5048\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.6932 - accuracy: 0.5074 - val_loss: 0.6941 - val_accuracy: 0.5062\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6928 - accuracy: 0.5062 - val_loss: 0.6934 - val_accuracy: 0.5062\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.6929 - accuracy: 0.5076 - val_loss: 0.6938 - val_accuracy: 0.5075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7805a582a170>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9ziz5wWgTLS"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}