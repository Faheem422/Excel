{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vR6C9i-fyLvG"
      },
      "outputs": [],
      "source": [
        "docs = ['go pakistan',\n",
        "\t\t'pakistan pakistan',\n",
        "\t\t'hip hip hurray',\n",
        "\t\t'jeetega bhai jeetega pakistan jeetega',\n",
        "\t\t'pakistan zindabad',\n",
        "\t\t'babar azam',\n",
        "\t\t'afridi afridi']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "xRzvJNh1mRQW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "2IhkPg6YmRYT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP5g_Tmin4AG",
        "outputId": "105891ec-6698-4b87-8c49-80decf914514"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOv8NrFFmRcE",
        "outputId": "69947045-d046-44cf-90cb-96a09b4436a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1], [1, 1], [3, 3, 6], [2, 7, 2, 1, 2], [1, 8], [9, 10], [4, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "sequences = pad_sequences(sequences,padding='post')\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG1RqcLnmRkA",
        "outputId": "5d596c68-15d3-4e04-f014-fecc7c044f36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  1,  0,  0,  0],\n",
              "       [ 1,  1,  0,  0,  0],\n",
              "       [ 3,  3,  6,  0,  0],\n",
              "       [ 2,  7,  2,  1,  2],\n",
              "       [ 1,  8,  0,  0,  0],\n",
              "       [ 9, 10,  0,  0,  0],\n",
              "       [ 4,  4,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
      ],
      "metadata": {
        "id": "RrsUPEOXGXCZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(17,output_dim=2,input_length=5)) # you have to give three things (no of unique words, output dimension of embeddings, how meny words you have)\n",
        "# output dim = 2 means your are representing each word by 2 numbers,\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETWEOn4wmRzd",
        "outputId": "b96ad556-9cba-4848-e466-599b13b1c0a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5, 2)              34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34 (136.00 Byte)\n",
            "Trainable params: 34 (136.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile('adam','accuracy')"
      ],
      "metadata": {
        "id": "R68ghDfNmSAC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(sequences)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooYWO2NwoKoQ",
        "outputId": "7f08a2d1-a413-46e4-c9cc-ed74aa28cc41"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 112ms/step\n",
            "[[[ 0.03879647 -0.02523152]\n",
            "  [ 0.04729637  0.046517  ]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]]\n",
            "\n",
            " [[ 0.04729637  0.046517  ]\n",
            "  [ 0.04729637  0.046517  ]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]]\n",
            "\n",
            " [[ 0.04179371 -0.00964843]\n",
            "  [ 0.04179371 -0.00964843]\n",
            "  [-0.04598373 -0.0274715 ]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]]\n",
            "\n",
            " [[-0.00943267 -0.01289005]\n",
            "  [-0.01118387 -0.02871189]\n",
            "  [-0.00943267 -0.01289005]\n",
            "  [ 0.04729637  0.046517  ]\n",
            "  [-0.00943267 -0.01289005]]\n",
            "\n",
            " [[ 0.04729637  0.046517  ]\n",
            "  [-0.01465169  0.04534661]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]]\n",
            "\n",
            " [[ 0.00647781 -0.02874732]\n",
            "  [ 0.00072552 -0.02985121]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]]\n",
            "\n",
            " [[-0.01657698 -0.04124665]\n",
            "  [-0.01657698 -0.04124665]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]\n",
            "  [-0.00739961 -0.01178045]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
      ],
      "metadata": {
        "id": "yrM0IXVamPLn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train),(X_test,y_test) = imdb.load_data()"
      ],
      "metadata": {
        "id": "4aH4HVjcyq1f",
        "outputId": "f4644f83-b066-46fa-ddd8-92f3007f6996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train,padding='post',maxlen=50)\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=50)"
      ],
      "metadata": {
        "id": "cu2UOZGUzAEF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aO412Krkz7EO",
        "outputId": "c6ef3d81-10a2-41eb-cbc9-36c8ccd37983"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 2, input_length=50))\n",
        "model.add(SimpleRNN(32,return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWXhm8vP_DO-",
        "outputId": "f02614de-76ad-4fe8-ee96-7320dc8355d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 50, 2)             20000     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                1120      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21153 (82.63 KB)\n",
            "Trainable params: 21153 (82.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train,epochs=5,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGCAZ7Rm_fqH",
        "outputId": "fd52f4ab-8740-4d46-e9ca-f14afb291b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 58s 70ms/step - loss: 0.6807 - acc: 0.5510 - val_loss: 0.6052 - val_acc: 0.6736\n",
            "Epoch 2/5\n",
            "128/782 [===>..........................] - ETA: 34s - loss: 0.5473 - acc: 0.7290"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAQETwiZikEY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}